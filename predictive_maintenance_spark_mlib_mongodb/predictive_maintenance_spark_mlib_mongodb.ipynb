{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7909a89-f162-4c99-9d57-b89196614b70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "257fe21d-68bb-463d-8a2b-0eafb30eefa2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Logistic Regression Example\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "903115b7-c35f-46f3-8ccc-5504b253c7e0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"/FileStore/tables/train_processed.csv\"  \n",
    "data = spark.read.csv(data_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "113d201f-b56d-4090-90cb-e9b66ebde335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- 0: integer (nullable = true)\n |-- 1: integer (nullable = true)\n |-- 2: double (nullable = true)\n |-- 3: double (nullable = true)\n |-- 4: double (nullable = true)\n |-- 5: double (nullable = true)\n |-- 6: double (nullable = true)\n |-- 7: double (nullable = true)\n |-- 8: double (nullable = true)\n |-- 9: double (nullable = true)\n |-- 10: double (nullable = true)\n |-- 11: double (nullable = true)\n |-- 12: double (nullable = true)\n |-- 13: double (nullable = true)\n |-- 14: double (nullable = true)\n |-- 15: double (nullable = true)\n |-- 16: double (nullable = true)\n |-- 17: double (nullable = true)\n |-- 18: double (nullable = true)\n |-- 19: double (nullable = true)\n |-- 20: double (nullable = true)\n |-- 21: integer (nullable = true)\n |-- 22: integer (nullable = true)\n |-- 23: double (nullable = true)\n |-- 24: double (nullable = true)\n |-- 25: double (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c85c7fab-bba5-46f3-8a06-1bff46aa754a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preview of the training data:\n+---+---+-------+-------+-----+------+------+-------+-------+-----+-----+------+-------+-------+---+-----+------+-------+-------+------+----+---+----+-----+-----+-------+\n|  0|  1|      2|      3|    4|     5|     6|      7|      8|    9|   10|    11|     12|     13| 14|   15|    16|     17|     18|    19|  20| 21|  22|   23|   24|     25|\n+---+---+-------+-------+-----+------+------+-------+-------+-----+-----+------+-------+-------+---+-----+------+-------+-------+------+----+---+----+-----+-----+-------+\n|  1|  1|-7.0E-4|-4.0E-4|100.0|518.67|641.82| 1589.7| 1400.6|14.62|21.61|554.36|2388.06|9046.19|1.3|47.47|521.66|2388.02|8138.62|8.4195|0.03|392|2388|100.0|39.06| 23.419|\n|  1|  2| 0.0019|-3.0E-4|100.0|518.67|642.15|1591.82|1403.14|14.62|21.61|553.75|2388.04|9044.07|1.3|47.49|522.28|2388.07|8131.49|8.4318|0.03|392|2388|100.0| 39.0|23.4236|\n|  1|  3|-0.0043| 3.0E-4|100.0|518.67|642.35|1587.99| 1404.2|14.62|21.61|554.26|2388.08|9052.94|1.3|47.27|522.42|2388.03|8133.23|8.4178|0.03|390|2388|100.0|38.95|23.3442|\n|  1|  4| 7.0E-4|    0.0|100.0|518.67|642.35|1582.79|1401.87|14.62|21.61|554.45|2388.11|9049.48|1.3|47.13|522.86|2388.08|8133.83|8.3682|0.03|392|2388|100.0|38.88|23.3739|\n|  1|  5|-0.0019|-2.0E-4|100.0|518.67|642.37|1582.85|1406.22|14.62|21.61| 554.0|2388.06|9055.15|1.3|47.28|522.19|2388.04| 8133.8|8.4294|0.03|393|2388|100.0| 38.9|23.4044|\n+---+---+-------+-------+-----+------+------+-------+-------+-----+-----+------+-------+-------+---+-----+------+-------+-------+------+----+---+----+-----+-----+-------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "print(\"Preview of the training data:\")\n",
    "data.show(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2387f43b-a90a-4c76-add8-fa420b98177b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "column_names = ['label', 'engine', 'cycle', 'setting1', 'setting2', 'setting3',\n",
    "                'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5',\n",
    "                'sensor6', 'sensor7', 'sensor8', 'sensor9', 'sensor10',\n",
    "                'sensor11', 'sensor12', 'sensor13', 'sensor14', 'sensor15',\n",
    "                'sensor16', 'sensor17', 'sensor18', 'sensor19', 'sensor20',\n",
    "                'sensor21']\n",
    "\n",
    "# Rename the columns in the DataFrame\n",
    "for old_name, new_name in zip(data.columns, column_names):\n",
    "    data = data.withColumnRenamed(old_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf9e120a-41b4-4edf-85c5-1ca0dc5b0f69",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n|label|engine|  cycle|setting1|setting2|setting3|sensor1|sensor2|sensor3|sensor4|sensor5|sensor6|sensor7|sensor8|sensor9|sensor10|sensor11|sensor12|sensor13|sensor14|sensor15|sensor16|sensor17|sensor18|sensor19|sensor20|\n+-----+------+-------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n|    1|     1|-7.0E-4| -4.0E-4|   100.0|  518.67| 641.82| 1589.7| 1400.6|  14.62|  21.61| 554.36|2388.06|9046.19|    1.3|   47.47|  521.66| 2388.02| 8138.62|  8.4195|    0.03|     392|    2388|   100.0|   39.06|  23.419|\n|    1|     2| 0.0019| -3.0E-4|   100.0|  518.67| 642.15|1591.82|1403.14|  14.62|  21.61| 553.75|2388.04|9044.07|    1.3|   47.49|  522.28| 2388.07| 8131.49|  8.4318|    0.03|     392|    2388|   100.0|    39.0| 23.4236|\n|    1|     3|-0.0043|  3.0E-4|   100.0|  518.67| 642.35|1587.99| 1404.2|  14.62|  21.61| 554.26|2388.08|9052.94|    1.3|   47.27|  522.42| 2388.03| 8133.23|  8.4178|    0.03|     390|    2388|   100.0|   38.95| 23.3442|\n|    1|     4| 7.0E-4|     0.0|   100.0|  518.67| 642.35|1582.79|1401.87|  14.62|  21.61| 554.45|2388.11|9049.48|    1.3|   47.13|  522.86| 2388.08| 8133.83|  8.3682|    0.03|     392|    2388|   100.0|   38.88| 23.3739|\n|    1|     5|-0.0019| -2.0E-4|   100.0|  518.67| 642.37|1582.85|1406.22|  14.62|  21.61|  554.0|2388.06|9055.15|    1.3|   47.28|  522.19| 2388.04|  8133.8|  8.4294|    0.03|     393|    2388|   100.0|    38.9| 23.4044|\n+-----+------+-------+--------+--------+--------+-------+-------+-------+-------+-------+-------+-------+-------+-------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.show(5)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "471d15f9-abad-47fc-a896-8504e47d5e0a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the feature vector and label\n",
    "feature_columns = ['engine', 'cycle', 'setting1', 'setting2', 'setting3',\n",
    "                   'sensor1', 'sensor2', 'sensor3', 'sensor4', 'sensor5',\n",
    "                   'sensor6', 'sensor7', 'sensor8', 'sensor9', 'sensor10',\n",
    "                   'sensor11', 'sensor12', 'sensor13', 'sensor14', 'sensor15',\n",
    "                   'sensor16', 'sensor17', 'sensor18', 'sensor19', 'sensor20']\n",
    "# Combine features into a single feature vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63f5a03d-2b23-4acf-9e7a-ede7ce104b21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n|            features|label|prediction|\n+--------------------+-----+----------+\n|[1.0,-0.005,3.0E-...|   81|      63.0|\n|[1.0,-0.0037,2.0E...|   80|      77.0|\n|[1.0,-0.0034,3.0E...|   88|      45.0|\n|[1.0,-0.0033,3.0E...|  100|      63.0|\n|[1.0,-0.0021,-4.0...|   25|      37.0|\n|[1.0,-0.0021,3.0E...|   33|      53.0|\n|[1.0,-0.002,-3.0E...|   53|      40.0|\n|[1.0,-0.0018,6.0E...|    2|      65.0|\n|[1.0,-0.0016,5.0E...|   18|      45.0|\n|[1.0,-0.0014,-4.0...|   96|      57.0|\n+--------------------+-----+----------+\nonly showing top 10 rows\n\nTest set accuracy = 0.09\n"
     ]
    }
   ],
   "source": [
    "final_data = data.select(\"features\", \"label\")  \n",
    "train_data, test_data = final_data.randomSplit([0.7, 0.3], seed=42)\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\")\n",
    "lr_model = lr.fit(train_data)\n",
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(10)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Test set accuracy = {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bf4ff104-ea69-4fd5-a507-1b2c282c986d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+----------+\n|            features|label|indexedLabel|prediction|\n+--------------------+-----+------------+----------+\n|[1.0,-0.005,3.0E-...|   81|        19.0|       1.0|\n|[1.0,-0.0037,2.0E...|   80|        70.0|       7.0|\n|[1.0,-0.0034,3.0E...|   88|        26.0|       5.0|\n|[1.0,-0.0033,3.0E...|  100|        56.0|       0.0|\n|[1.0,-0.0021,-4.0...|   25|        31.0|      71.0|\n|[1.0,-0.0021,3.0E...|   33|        59.0|      21.0|\n|[1.0,-0.002,-3.0E...|   53|        62.0|       3.0|\n|[1.0,-0.0018,6.0E...|    2|         4.0|       4.0|\n|[1.0,-0.0016,5.0E...|   18|        41.0|       8.0|\n|[1.0,-0.0014,-4.0...|   96|         2.0|      33.0|\n+--------------------+-----+------------+----------+\nonly showing top 10 rows\n\nRandom Forest Test set accuracy = 0.11\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"features\", numTrees=100)\n",
    "pipeline = Pipeline(stages=[indexer, rf])\n",
    "\n",
    "rf_model = pipeline.fit(train_data)\n",
    "rf_predictions = rf_model.transform(test_data)\n",
    "rf_predictions.select(\"features\", \"label\", \"indexedLabel\", \"prediction\").show(10)\n",
    "\n",
    "# Evaluate the model\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Random Forest Test set accuracy = {rf_accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c8563c3-39be-41e1-973d-c5f1f3483663",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "predictive_maintenance_spark_mlib_mongodb",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
